{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034367fd",
   "metadata": {},
   "source": [
    "# Tweet Sentiment Analysis Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ca00a",
   "metadata": {},
   "source": [
    "[Data Source](https://data.world/crowdflower/brands-and-product-emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2044db6e",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "Our goal is to build a proof-of-concept classifier which would allow Apple to monitor sentiment toward its products (and the products of its top competitors) on Twitter.\n",
    "\n",
    "In particular, Apple needs to be able to monitor *negative sentiment* towards its products and that of its competitors to respond quickly to customer dissatisfaction to resolve the issue (or, in the case of its competitors, to proactively avoid their pain points.)\n",
    "\n",
    "## Data Understanding\n",
    "\n",
    "We have a collection of ~9,000 tweets concerning Apple, Android and Google products with the sentiment labeled (\"positive\", \"negative\", \"neutral\", or \"I can't tell\") and the object of the sentiment in the tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42710d4",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e4f2127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed for reproducibility\n",
    "seed = 3490\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.container import BarContainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import gensim.downloader\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972be2a9",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f63d4ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text   \n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  \\\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at   \n",
       "0                          iPhone  \\\n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from file; encoding is \"latin1\"\n",
    "data = pd.read_csv('data/judge-1377884607_tweet_product_company.csv', encoding='latin1')\n",
    "\n",
    "# inspect first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d5311ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd9eaa",
   "metadata": {},
   "source": [
    "How many tweets contains #SXSW or #sxsw? (Answer: most of them.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41728d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = data.dropna().copy()\n",
    "data_list['tweet_words'] = data_list.tweet_text.map(lambda x: x.split())\n",
    "exploded = data_list.reset_index().rename({'index': 'true_index'}, axis=1).explode('tweet_words')\n",
    "about_sxsw = exploded.loc[(exploded.tweet_words == '#SXSW') | (exploded.tweet_words == '#sxsw')].true_index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dc43a1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@mention #SXSW don't forget @mention to plan your schedule. Plus our free iphone app {link}\n",
      "Outside of 9:30 panels which 75% of people skip I can barely get anything to work on my iPhone. #sxsw needs to shrink by 10k people.\n",
      "I want one!! It's not a rumor: Apple is opening up a temporary store in downtown Austin for #SXSW and the iPad 2 launch {link}\n",
      "If you haven't waited in line for an Apple product you're missing out on an important rite of passage.  #sxsw\n",
      "Apple set to open popup shop in core of #SXSW action {link} Geeks need #iPad2 love!\n"
     ]
    }
   ],
   "source": [
    "for tweet in data.tweet_text.loc[about_sxsw].sample(5):\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24582b16",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0de4e0",
   "metadata": {},
   "source": [
    "The column names are a mouthful (\"is_there_an_emotion_directed_at_a_brand_or_product\"), so let's rename them for ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8180b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>object_of_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text object_of_sentiment   \n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone  \\\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "          sentiment  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename last two columns, in place\n",
    "data.rename({'emotion_in_tweet_is_directed_at': 'object_of_sentiment',\n",
    "             'is_there_an_emotion_directed_at_a_brand_or_product': 'sentiment'}, axis=1, inplace=True)\n",
    "# inspect first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65df63e",
   "metadata": {},
   "source": [
    "Now let's explore the distribution of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0efce112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "No emotion toward brand or product    5389\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ec636d",
   "metadata": {},
   "source": [
    "Sample a few tweets which have unlabeled sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c8aaa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally got my #SXSW schedule on my #google calendar. #coudbeeasier\n",
      "funny! iphone correction? RT @mention Dashing off to learn a thing or two about longhorn journalism #SXSW\n",
      "&quot;Do you know what Apple is really good at? Making you feel bad about your Xmas present!&quot; - Seth Meyers on iPad2 #sxsw #doyoureallyneedthat?\n",
      "+1 ÛÏ@mention +1 RT @mention Petricone says Google TV is just a browser. I don't think that's correct. #SXSWÛ\n",
      "RT @mention Gary Vaynerchuck lÌ_gger ner winelibrary.tv och slÌ_pper i stÌ_llet Iphone-appen Daily Grape. #thankyoueconomy #sxsw #swesxsw\n"
     ]
    }
   ],
   "source": [
    "for i in data.loc[data.sentiment==\"I can't tell\"].sample(5, random_state=seed).index:\n",
    "    print(data.loc[i, 'tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015296e2",
   "metadata": {},
   "source": [
    "Only one of these is clearly negative. However, forcing the classifier to treat them as positive, negative or neutral would probably yield some valuable insights for the brand (example: why don't you use your iPad on the go? Can the iPhone alarm clock be improved?) \\*Sorry, I didn't set the random_state initially! These comments were in reference to a different sample of tweets.\n",
    "\n",
    "With that being said, the records with unlabeled sentiment represent only a small portion of the dataset, and introducing semi-supervised labels here may have an unexpected effect given that the original labellers already classified these tweets as ambiguous. I will drop these records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d097f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"I can't tell\" in sentiment column with null\n",
    "data.sentiment = data.sentiment.replace({\"I can't tell\": None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd9b3389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop records with null value for sentiment\n",
    "data.dropna(subset='sentiment', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5142be",
   "metadata": {},
   "source": [
    "Now let's explore the distribution of products discussed in these tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82473539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title('Objects of Sentiment in Tweets')\n",
    "\n",
    "data.object_of_sentiment.value_counts().plot(kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70c0a74",
   "metadata": {},
   "source": [
    "We have the most data on Apple products, and a little sprinkling of data on Google and Android products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa5d4a",
   "metadata": {},
   "source": [
    "What is the sentiment breakdown by object?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6285d8",
   "metadata": {},
   "source": [
    "Before we answer this question, first note that more than half of records do not have an object of sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8492192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5655"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.object_of_sentiment.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d128ceb",
   "metadata": {},
   "source": [
    "Check how many of these null sentiment records correspond to tweets which are neutral or unlabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6582c511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5298"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[(data.sentiment=='No emotion toward brand or product') | (data.sentiment==\"I can't tell\"),\n",
    "         'object_of_sentiment'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a5cca4",
   "metadata": {},
   "source": [
    "There are 5298 records for which sentiment is unknown or neutral, and the \"object_of_sentiment\" value is null. But this means that there are a few records for which no object is given, despite a positive or negative sentiment being recorded.\n",
    "\n",
    "Let's view an example of such a tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8274131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My iPhone says it can't connect to the Internet even though #sxsw wifi works great on my computer. Any suggestions?\n",
      "RT @mention The Web DesignerÛªs Guide to iOS (and Android) Apps, today @mention 10 a.m! {link} #sxsw\n",
      "Imagine if every company had the 20% concept like Google. #bavcID #SXSW\n"
     ]
    }
   ],
   "source": [
    "for i in data.loc[((data.sentiment=='Positive emotion') | (data.sentiment=='Negative emotion')) &\n",
    "                  (data.object_of_sentiment.isna())].sample(3, random_state=seed).index:\n",
    "    print(data.loc[i, 'tweet_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8ed178",
   "metadata": {},
   "source": [
    "One approach to deal with these null objects is to classify them using the labeled data as training data (semi-supervised learning.)\n",
    "\n",
    "We may mis-classify some tweets -- for example, tweet 64 is not directed at a specific Apple product at all -- but hopefully we can capture the fact that some of these *are* clearly directed at specific products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b42a3a",
   "metadata": {},
   "source": [
    "Before we complete the above semi-supervised learning task for the \"object_of_sentiment\" category, let's look at the current distribution of positive, negative and neutral tweets by product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9fac747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            sentiment  count\n",
       "0                    Positive emotion    793\n",
       "1                    Negative emotion    125\n",
       "2  No emotion toward brand or product     24"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.object_of_sentiment=='iPad', 'sentiment'].value_counts().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c04ac08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(15, 10))\n",
    "\n",
    "# set up color map for negative, positive and neutral tweets\n",
    "viridis = mpl.colormaps['viridis'].resampled(3)\n",
    "\n",
    "for n, product in enumerate(np.unique(data.object_of_sentiment.to_list())[:-1]):\n",
    "    # get sentiment counts for this product\n",
    "    df = data.loc[data.object_of_sentiment==product, 'sentiment'].value_counts().to_frame().reset_index()\n",
    "\n",
    "    # plot bar chart\n",
    "    df.plot(kind='barh', ax=ax[n//3][n%3])\n",
    "    \n",
    "    # set colors for each bar according to whether it is the count of positive, negative or neutral tweets\n",
    "    bars = [i for i in ax[n//3][n%3].containers if isinstance(i, BarContainer)]\n",
    "    colors = df.sentiment.replace({'Positive emotion': 2,\n",
    "                                   'Negative emotion': 0,\n",
    "                                   'No emotion toward brand or product': 1})\n",
    "    for i in range(3):\n",
    "        bars[0][i].set_color(viridis(colors[i]/2))\n",
    "    \n",
    "    # fix labels, remove legend\n",
    "    ax[n//3][n%3].set_yticklabels(df['sentiment'])\n",
    "    ax[n//3][n%3].get_legend().remove()\n",
    "    \n",
    "    # set title\n",
    "    ax[n//3][n%3].set_title(f'{product}')\n",
    "    \n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09663ce",
   "metadata": {},
   "source": [
    "The iPhone has the highest ratio of negative to positive emotion tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59da3cc6",
   "metadata": {},
   "source": [
    "Let's dig in a little more to customer sentiment toward Apple products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7eebc536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>object_of_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text object_of_sentiment   \n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone  \\\n",
       "\n",
       "          sentiment  \n",
       "0  Negative emotion  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44720a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative emotion toward iPhone:\n",
      "With just my iPhone and iPad on me, I feel very unequipped compared to everyone else. Dang! #sxsw\n",
      "\n",
      "\n",
      "No emotion toward brand or product toward iPhone:\n",
      "Still using the original first-generation iPhone. Wondering if this will get me kicked out of #SXSW\n",
      "\n",
      "\n",
      "Positive emotion toward iPhone:\n",
      "@mention Feature @mention for the iPhone. We will be all over #SXSW this week!\n",
      "\n",
      "\n",
      "Negative emotion toward iPad or iPhone App:\n",
      "NYT app for iPad: not &quot;here's an amazing way to serve our readership,&quot; more &quot;here's a market opportunity we can't ignore.&quot; #sxsw #newsapps\n",
      "\n",
      "\n",
      "No emotion toward brand or product toward iPad or iPhone App:\n",
      "Just got @mention new iPhone app, The Dialy Grape: {link} #sxsw #thankyou\n",
      "\n",
      "\n",
      "Positive emotion toward iPad or iPhone App:\n",
      "Unexpected geekout moment of #sxsw so far: talked with the guys who are bringing the Traveller RPG to the iPhone.\n",
      "\n",
      "\n",
      "Negative emotion toward iPad:\n",
      "In iPad Design Headaches: Take Two Tablets, Call Me in the AM panel - excited to hear @mention live! #sxsw\n",
      "\n",
      "\n",
      "No emotion toward brand or product toward iPad:\n",
      "@mention You can get an iPad 1 for under $350 now. And they'll be $99 before you know it. Look at iPhone. #newsapps #sxsw\n",
      "\n",
      "\n",
      "Positive emotion toward iPad:\n",
      "So I bought an iPad on impulse! Must be something in the water at #sxsw!\n",
      "\n",
      "\n",
      "Negative emotion toward Other Apple product or service:\n",
      "Design for iPad is like a design 101 class. Will someone give a talk and assume that we didn't all ditch our previous experience #sxsw\n",
      "\n",
      "\n",
      "No emotion toward brand or product toward Other Apple product or service:\n",
      "From #Apple to Naomi Campbell: pop-up stores are all the rage: {link} #sxsw\n",
      "\n",
      "\n",
      "Positive emotion toward Other Apple product or service:\n",
      "@mention #sxsw - free tunage on iTunes {link}\n",
      "\n",
      "\n",
      "Negative emotion toward Apple:\n",
      "Too quotable --&gt; RT ÛÏ@mention &quot;Apple is the most elegant fascist company in America.&quot; #flip-board #SXSW\n",
      "\n",
      "\n",
      "No emotion toward brand or product toward Apple:\n",
      "Austin has two Apple Stores, actually. RT @mention @mention Brian - Austin doesn't have an Apple store but they built a pop up one for #SXSW\n",
      "\n",
      "\n",
      "Positive emotion toward Apple:\n",
      "Apple's pop-up store at #SXSW on the day of the iPad2 release could be the most genius move in marketing history.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "apple_products = ['iPhone', 'iPad or iPhone App', 'iPad', 'Other Apple product or service', 'Apple']\n",
    "sentiments = np.unique(data.sentiment)\n",
    "\n",
    "for product in apple_products:\n",
    "    for sentiment in sentiments:\n",
    "        try:\n",
    "            print(f'{sentiment} toward {product}:')\n",
    "            text = data.loc[\n",
    "                (data.object_of_sentiment==product)&(data.sentiment==sentiment), 'tweet_text'].sample(1).values[0]\n",
    "            print(text)\n",
    "            print('\\n')\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3308b11a",
   "metadata": {},
   "source": [
    "How many tweets are concerning Apple?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "712a40d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2402, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.object_of_sentiment.isin(apple_products)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "97b89376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.268770280854873"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2402 / len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d93fafc",
   "metadata": {},
   "source": [
    "Roughly 27% of our data concerns Apple products."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69477444",
   "metadata": {},
   "source": [
    "## Semi-supervised Learning\n",
    "\n",
    "Apply semi-supervised learning to classify the object_of_sentiment for tweets with positive or negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e4fe3d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>object_of_sentiment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text object_of_sentiment   \n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...              iPhone  \\\n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...  iPad or iPhone App   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...                iPad   \n",
       "3  @sxsw I hope this year's festival isn't as cra...  iPad or iPhone App   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...              Google   \n",
       "\n",
       "          sentiment  \n",
       "0  Negative emotion  \n",
       "1  Positive emotion  \n",
       "2  Positive emotion  \n",
       "3  Negative emotion  \n",
       "4  Positive emotion  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all tweets with positive or negative sentiment\n",
    "emotive_tweets = data.loc[(data.sentiment=='Positive emotion') | (data.sentiment=='Negative emotion')]\n",
    "emotive_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "06080b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into \"train\" and \"predict\"\n",
    "train = emotive_tweets.loc[emotive_tweets.object_of_sentiment.isna()==False]\n",
    "predict = emotive_tweets.loc[emotive_tweets.object_of_sentiment.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "564e3ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check shapes\n",
    "train.shape[0] + predict.shape[0] == emotive_tweets.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb8251",
   "metadata": {},
   "source": [
    "Now, we want to build a classifier to classify the object_of_sentiment for the \"predict\" set based on the labels in the \"train\" set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8a47452",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train['object_of_sentiment']\n",
    "train_features = train['tweet_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f96ad",
   "metadata": {},
   "source": [
    "We need to label encode the target, then vectorize the tweet text.\n",
    "\n",
    "We now run into the problem that we are going to have when building the sentiment classifier; there are many different ways that we could preprocess the tweet text prior to modeling, and when you combine this with all of the classification algorithms we could use and their hyperparameters to be tuned, we have a truly large search space for the \"best\" model to do the job.\n",
    "\n",
    "For this reason, I plan to drop this data for now and return to this piece of the project after building out a classifier below. I will use whatever preprocessing techniques resulted in the best performance for identifying the object of the sentiment, and I will apply that preprocessing technique to the \"training data\" for labeling the unlabeled object_of_sentiment values, then build a classifier to label these missing values.\n",
    "\n",
    "When I add the newly labeled data to the rest of the training data and refit the best-performing classifier as determined below, if the performance improves or stays the same, I will keep it. Otherwise, this data will be permanently dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378e3b5b",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c39b313",
   "metadata": {},
   "source": [
    "Our goal is to build a classifier which identifies the i.) sentiment and ii.) object of sentiment of a tweet.\n",
    "\n",
    "We are going to build the classifier in steps:\n",
    "\n",
    "1.) Classify a tweet as negative or not negative (positive or neutral, with no distinction between the two.)\n",
    "\n",
    "2.) Classify the object of the sentiment in a tweet.\n",
    "\n",
    "3.) Combine 1 and 2.\n",
    "\n",
    "4.) Classify a tweet as positive, negative or neutral and identify the object of the sentiment (if applicable.)\n",
    "\n",
    "It is not critically important that our classifier be able to distinguish between positive and neutral tweets (hence, it is the last step in our process.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fceaa689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                1\n",
       "object_of_sentiment    5655\n",
       "sentiment                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d4f878c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 8936 records.\n"
     ]
    }
   ],
   "source": [
    "# drop tweet that is missing tweet_text\n",
    "data.dropna(subset='tweet_text', inplace=True)\n",
    "print(f'We now have {data.shape[0]} records.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6de5d",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b1975bfc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5718,)\n",
      "(5718,)\n",
      "\n",
      "\n",
      "(1430,)\n",
      "(1430,)\n",
      "\n",
      "\n",
      "(1788,)\n",
      "(1788,)\n"
     ]
    }
   ],
   "source": [
    "# separate features and target\n",
    "X = data['tweet_text']\n",
    "y = data['sentiment']\n",
    "\n",
    "# label encode the target\n",
    "le = LabelEncoder()\n",
    "y_encoded = pd.Series(le.fit_transform(y), index=y.index)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=seed)\n",
    "\n",
    "# train val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed)\n",
    "\n",
    "# check shapes\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print('\\n')\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "print('\\n')\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f3167720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.602134\n",
       "2    0.335607\n",
       "0    0.062260\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c6555a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Negative emotion',\n",
       " 1: 'No emotion toward brand or product',\n",
       " 2: 'Positive emotion'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip([0, 1, 2], le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d1df65",
   "metadata": {},
   "source": [
    "We may have some difficulty capturing the negative class due to its tiny minority! We may even have some difficulty capturing the positive class, also; the neutral class is so big."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e48dc",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e3597",
   "metadata": {},
   "source": [
    "I am going to try three different methods of preprocessing the tweet text to pass in to the model. The tweets need to be \"clean\" (lower cased, with punctuation removed and, ideally, some form of tokenization applied) before these methods can be applied, so we are going to do that preprocessing work first. We will also remove some common English stop words.\n",
    "\n",
    "The vectorization / embedding techniques to then be applied are:\n",
    "- count or term frequency inverse document frequency vectorization (using Scikit Learn's implementations; we will try both)\n",
    "- using pretrained GloVe embeddings and a mean word embedding for each tweet\n",
    "- training a Word2Vec model on our corpus to obtain embeddings (using gensim) and using a mean word embedding for each tweet\n",
    "\n",
    "A fourth and final possible technique to be applied is stacking a combination of these embeddings/vectorizations to pass into the model, along with any other potentially helpful features (e.g. TextBlob's sentiment analysis polarity results for the tweet.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2f9cdc",
   "metadata": {},
   "source": [
    "#### General Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1e551",
   "metadata": {},
   "source": [
    "We can apply general clean up techniques and tokenization to the entire training data without leakage, so we will do that first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac2f4d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up (remove punctuation & change to lower case) tweets & remove english stopwords\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def clean_up(tweet):\n",
    "    return ' '.join([word.strip(string.punctuation).lower() for word in tweet.split() if\n",
    "                     word not in stopwords_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7d05b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5390    rt mention android developers friends let's ha...\n",
       "5237    rt mention ipad design tip looks like physical...\n",
       "7148                            apple store atx link sxsw\n",
       "7206    my life would much better ipad brainwashed lin...\n",
       "5416    rt mention apple autocorrect weird ogilvy auto...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.apply(clean_up).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eead14",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56139d57",
   "metadata": {},
   "source": [
    "We can employ stemming or lemmatization to obtain tokens for vectorization.\n",
    "\n",
    "Stemming is very simple with nltk's Porter Stemmer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "653b5d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi i'm rob and i'm go swim tomorrow woohoo\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "def get_stems(tweet):\n",
    "    '''Takes in a string of words and outputs a string of stemmed tokens.'''\n",
    "    stemmer = PorterStemmer()\n",
    "    return ' '.join([stemmer.stem(word) for word in tweet.split()])\n",
    "\n",
    "# test\n",
    "get_stems(\"hi i'm rob and i'm going swimming tomorrow woohoo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be843d9",
   "metadata": {},
   "source": [
    "Lemmatization looks more complicated, but this is only because the lemmatizer from WordNet works best if part-of-speech tags are passed to it along with the word itself. Most of the code below generates a wordnet version of a part of speech tag for a word and passes it in to the lemmatizer along with the word itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87e71864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hi i'm rob and i'm go swim tomorrow woohoo\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "\n",
    "# imports\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "# helper function to get wordnet pos_tags from nltk pos_tags\n",
    "def get_wordnet_pos(tag):\n",
    "    '''Convert POS tags generated by nltk.pos_tag to wordnet tags, for use with word net\n",
    "    lemmatizer provided in the nltk.stem.wordnet package.'''\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    \n",
    "# define function to apply lemmatizer to wordnet-tagged words to get lemmas\n",
    "def get_lemmas(tweet):\n",
    "    '''Takes in a string (tweet) and returns string of lemmatized tokens.'''\n",
    "    # instantiate word net lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    nltk_pos_tags = nltk.pos_tag(tweet.split()) # list of (word, pos_tag)\n",
    "    \n",
    "    wordnet_pos_tags = [(pair[0], get_wordnet_pos(pair[1])) for pair in nltk_pos_tags]\n",
    "    \n",
    "    return ' '.join([lemmatizer.lemmatize(*tagged_word) for tagged_word in wordnet_pos_tags])\n",
    "\n",
    "# test\n",
    "get_lemmas(\"hi i'm rob and i'm going swimming tomorrow woohoo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d72592fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stemmed and lemmatized tokens for training & validation data\n",
    "X_train_stems = X_train.apply(clean_up).apply(get_stems)\n",
    "X_train_lemmas = X_train.apply(clean_up).apply(get_lemmas)\n",
    "\n",
    "X_val_stems = X_val.apply(clean_up).apply(get_stems)\n",
    "X_val_lemmas = X_val.apply(clean_up).apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "586f4ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5390    rt mention android develop friend let' hang 12...\n",
       "5237    rt mention ipad design tip look like physic ob...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_stems.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "03b34973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5390    rt mention android developer friends let's han...\n",
       "5237    rt mention ipad design tip look like physical ...\n",
       "Name: tweet_text, dtype: object"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lemmas.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbb7a6",
   "metadata": {},
   "source": [
    "We see an example of stemming versus lemmatization in tweet 5237: stemming results in \"physic\", lemmatization results in \"physical\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27587cf3",
   "metadata": {},
   "source": [
    "The classifiers we will test out with are preprocessed data are random forest, naive bayes and support vector machine. We are not testing logistic regression because it is not particularly suited to a multi-class classification problem, and we are not using KNN because it is possible that two tweets which are both positive will contain very different content.\n",
    "\n",
    "I will store my results in the `model_eval` dictionary below which can easily be displayed as a DataFrame to view the model tuning process over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dc40be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = {'tokenization': [], 'preprocessing': [], 'classifier': [], 'score': []}\n",
    "\n",
    "def score_model(model, X_train, y_train, X_val, y_val, token, preprocess, clf):\n",
    "    global model_eval\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "    except:\n",
    "        print('Error fitting model; check training data. Is it scaled? Try fitting separately to troubleshoot.')\n",
    "        return 0\n",
    "    \n",
    "    model_eval['tokenization'].append(token)\n",
    "    model_eval['preprocessing'].append(preprocess)\n",
    "    model_eval['classifier'].append(clf)\n",
    "    model_eval['score'].append(model.score(X_val, y_val))\n",
    "    \n",
    "    return pd.DataFrame(model_eval).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a4df8c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>mention</th>\n",
       "      <th>android</th>\n",
       "      <th>develop</th>\n",
       "      <th>friend</th>\n",
       "      <th>let</th>\n",
       "      <th>hang</th>\n",
       "      <th>12</th>\n",
       "      <th>30p</th>\n",
       "      <th>saturday</th>\n",
       "      <th>...</th>\n",
       "      <th>webmail</th>\n",
       "      <th>suppose</th>\n",
       "      <th>forb</th>\n",
       "      <th>mahalo</th>\n",
       "      <th>97</th>\n",
       "      <th>woop</th>\n",
       "      <th>youkidshavefun</th>\n",
       "      <th>tdg</th>\n",
       "      <th>exclud</th>\n",
       "      <th>interface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 6512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rt  mention  android  develop  friend  let  hang  12  30p  saturday   \n",
       "5390   0        0        0        0       0    0     0   0    0         0  \\\n",
       "5237   0        0        0        0       0    0     0   0    0         0   \n",
       "\n",
       "      ...  webmail  suppose  forb  mahalo  97  woop  youkidshavefun  tdg   \n",
       "5390  ...        0        0     0       0   0     0               0    0  \\\n",
       "5237  ...        0        0     0       0   0     0               0    0   \n",
       "\n",
       "      exclud  interface  \n",
       "5390       0          0  \n",
       "5237       0          0  \n",
       "\n",
       "[2 rows x 6512 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                                                    columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val.index, columns=count.vocabulary_)\n",
    "\n",
    "final_X_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29468229",
   "metadata": {},
   "source": [
    "For random forest and naive bayes, it is not strictly necessary to scale the data. Let's go ahead and get scores for these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9ecce406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.684615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokenization    preprocessing     classifier     score\n",
       "0         stem  count_vectorize  random_forest  0.676923\n",
       "1         stem  count_vectorize    naive_bayes  0.684615"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "rf = RandomForestClassifier(random_state=seed)\n",
    "nb = MultinomialNB()\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', 'count_vectorize', 'random_forest')\n",
    "score_model(nb, final_X_train, y_train, final_X_val, y_val, 'stem', 'count_vectorize', 'naive_bayes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c31ee",
   "metadata": {},
   "source": [
    "For a support vector machine classifier, we do need to scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16a19ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.684615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.653147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokenization    preprocessing      classifier     score\n",
       "0         stem  count_vectorize   random_forest  0.676923\n",
       "1         stem  count_vectorize     naive_bayes  0.684615\n",
       "2         stem  count_vectorize  support_vector  0.653147"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "scaled_X_train = ss.fit_transform(final_X_train)\n",
    "scaled_X_val = ss.transform(final_X_val)\n",
    "\n",
    "svc = SVC(random_state=seed)\n",
    "\n",
    "score_model(svc, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', 'count_vectorize', 'support_vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d34146",
   "metadata": {},
   "source": [
    "With stemming and count vectorization, Naive Bayes is in the lead.\n",
    "\n",
    "Now we need to tune these classifiers, then tune the preprocessing technique (count vectorization) itself.\n",
    "\n",
    "Before we do so, let's check the model scores with the same preprocessing technique, but lemmatization instead of stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "966efc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.684615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.653147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.679021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.683916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.647552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokenization    preprocessing      classifier     score\n",
       "1         stem  count_vectorize     naive_bayes  0.684615\n",
       "2         stem  count_vectorize  support_vector  0.653147\n",
       "3    lemmatize  count_vectorize   random_forest  0.679021\n",
       "4    lemmatize  count_vectorize     naive_bayes  0.683916\n",
       "5    lemmatize  count_vectorize  support_vector  0.647552"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refit count vectorizer and standard scaler with lemmatized data\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_lemmas).todense(), index=X_train_lemmas.index,\n",
    "                                                    columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_lemmas).todense(), index=X_val_lemmas.index,\n",
    "                           columns=count.vocabulary_)\n",
    "\n",
    "scaled_X_train = ss.fit_transform(final_X_train)\n",
    "scaled_X_val = ss.transform(final_X_val)\n",
    "\n",
    "# score models with new training and validation data\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'lemmatize', 'count_vectorize', 'random_forest')\n",
    "score_model(nb, final_X_train, y_train, final_X_val, y_val, 'lemmatize', 'count_vectorize', 'naive_bayes')\n",
    "score_model(svc, scaled_X_train, y_train, scaled_X_val, y_val, 'lemmatize', 'count_vectorize', 'support_vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0badaf9f",
   "metadata": {},
   "source": [
    "The best performing classifier so far is Naive Bayes, and it performs 0.1% better with stemming, rather than lemmatization, so we'll use the stemmed and count-vectorized data to tune our Naive Bayes classifier next. Then we can turn our attention back to tuning the count vectorizer itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "257acbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>mention</th>\n",
       "      <th>android</th>\n",
       "      <th>develop</th>\n",
       "      <th>friend</th>\n",
       "      <th>let</th>\n",
       "      <th>hang</th>\n",
       "      <th>12</th>\n",
       "      <th>30p</th>\n",
       "      <th>saturday</th>\n",
       "      <th>...</th>\n",
       "      <th>webmail</th>\n",
       "      <th>suppose</th>\n",
       "      <th>forb</th>\n",
       "      <th>mahalo</th>\n",
       "      <th>97</th>\n",
       "      <th>woop</th>\n",
       "      <th>youkidshavefun</th>\n",
       "      <th>tdg</th>\n",
       "      <th>exclud</th>\n",
       "      <th>interface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 6512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rt  mention  android  develop  friend  let  hang  12  30p  saturday   \n",
       "5390   0        0        0        0       0    0     0   0    0         0  \\\n",
       "5237   0        0        0        0       0    0     0   0    0         0   \n",
       "\n",
       "      ...  webmail  suppose  forb  mahalo  97  woop  youkidshavefun  tdg   \n",
       "5390  ...        0        0     0       0   0     0               0    0  \\\n",
       "5237  ...        0        0     0       0   0     0               0    0   \n",
       "\n",
       "      exclud  interface  \n",
       "5390       0          0  \n",
       "5237       0          0  \n",
       "\n",
       "[2 rows x 6512 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                            columns=count.vocabulary_)\n",
    "best_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                          columns=count.vocabulary_)\n",
    "best_X_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a525c4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=MultinomialNB(), param_grid={&#x27;alpha&#x27;: [1, 0.5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=MultinomialNB(), param_grid={&#x27;alpha&#x27;: [1, 0.5, 10]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=MultinomialNB(), param_grid={'alpha': [1, 0.5, 10]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'alpha': [1, 0.5, 10]}\n",
    "\n",
    "grid_search = GridSearchCV(nb, param_grid, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(best_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c285ebae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6631672570648949"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461102d1",
   "metadata": {},
   "source": [
    "There is very little that can be done to tune a Naive Bayes classifier. Changing the smoothing parameter didn't have a great effect.\n",
    "\n",
    "So we'll move on to tuning the count vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b3eb56a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6512"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a8c7c",
   "metadata": {},
   "source": [
    "Currently, the \"baseline\" count vectorizer has a vocabulary of 6512 lemmas.\n",
    "\n",
    "One technique we can try to improve the classifier's performance is limiting the vectorizer's vocabulary to only those words which show up often enough *and* little enough to qualify as being meaningful. (Example: 'the' shows up too often to provide information, but a word which only shows up once in the entire corpus also won't help us, for example, a specific person's username.)\n",
    "\n",
    "The below vectorizer has a \"maximum document frequency\" of 90% (only include a token if it appears in fewer than 90% of tweets) and a \"minimum document frequency\" of 5% (only include tokens which appear in more than 5% of all tweets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "42d473cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.653147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.679021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.683916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.647552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.9, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokenization                             preprocessing       classifier   \n",
       "2         stem                           count_vectorize   support_vector  \\\n",
       "3    lemmatize                           count_vectorize    random_forest   \n",
       "4    lemmatize                           count_vectorize      naive_bayes   \n",
       "5    lemmatize                           count_vectorize   support_vector   \n",
       "6         stem  CountVectorizer(max_df=0.9, min_df=0.05)  MultinomialNB()   \n",
       "\n",
       "      score  \n",
       "2  0.653147  \n",
       "3  0.679021  \n",
       "4  0.683916  \n",
       "5  0.647552  \n",
       "6  0.612587  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer(min_df=0.05, max_df=0.9)\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                                                    columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                           columns=count.vocabulary_)\n",
    "\n",
    "score_model(nb, final_X_train, y_train, final_X_val, y_val, 'stem', count, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e257e5b",
   "metadata": {},
   "source": [
    "Our model's score is worse (by about 7%.) Let's try a more conservative maximum document frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd132a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.679021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.683916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.647552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.9, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.95, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokenization                              preprocessing       classifier   \n",
       "3    lemmatize                            count_vectorize    random_forest  \\\n",
       "4    lemmatize                            count_vectorize      naive_bayes   \n",
       "5    lemmatize                            count_vectorize   support_vector   \n",
       "6         stem   CountVectorizer(max_df=0.9, min_df=0.05)  MultinomialNB()   \n",
       "7         stem  CountVectorizer(max_df=0.95, min_df=0.05)  MultinomialNB()   \n",
       "\n",
       "      score  \n",
       "3  0.679021  \n",
       "4  0.683916  \n",
       "5  0.647552  \n",
       "6  0.612587  \n",
       "7  0.612587  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer(min_df=0.05, max_df=0.95)\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                                                    columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                           columns=count.vocabulary_)\n",
    "\n",
    "score_model(nb, final_X_train, y_train, final_X_val, y_val, 'stem', count, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff91a7ad",
   "metadata": {},
   "source": [
    "Taking out information doesn't seem to be improving the model's performance, so let's try adding information by including bigrams in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f8fe4ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.683916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.647552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.9, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.95, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokenization                              preprocessing       classifier   \n",
       "4    lemmatize                            count_vectorize      naive_bayes  \\\n",
       "5    lemmatize                            count_vectorize   support_vector   \n",
       "6         stem   CountVectorizer(max_df=0.9, min_df=0.05)  MultinomialNB()   \n",
       "7         stem  CountVectorizer(max_df=0.95, min_df=0.05)  MultinomialNB()   \n",
       "8         stem        CountVectorizer(ngram_range=(1, 2))  MultinomialNB()   \n",
       "\n",
       "      score  \n",
       "4  0.683916  \n",
       "5  0.647552  \n",
       "6  0.612587  \n",
       "7  0.612587  \n",
       "8  0.690909  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                                                    columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                           columns=count.vocabulary_)\n",
    "\n",
    "score_model(nb, final_X_train, y_train, final_X_val, y_val, 'stem', count, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7692e83",
   "metadata": {},
   "source": [
    "Adding bigrams very slightly improved the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452bbed4",
   "metadata": {},
   "source": [
    "It's probably worth giving our other two classifiers a chance to be tuned as well before dismissing them out of hand (especially since there was so little to tune in the best model - there are a lot more knobs to turn for random forest, so perhaps it will improve significantly over the baseline.)\n",
    "\n",
    "Going back to simply X_train_stems, let's tune our random forest classifier next.\n",
    "\n",
    "Increasing the number of estimators should improve performance. Limiting the maximum depth of individual decision trees can help those trees not to overfit. It's possible that weighting the classes according to their ratios could improve performance as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "21d9f98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6411328610147508"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [100, 200, 300],\n",
    "              'max_depth': [2, 10, 20, 50],\n",
    "              'random_state': [seed]}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "grid_search = GridSearchCV(rf, param_grid, scoring='accuracy')\n",
    "\n",
    "grid_search.fit(final_X_train, y_train)\n",
    "\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e89d0",
   "metadata": {},
   "source": [
    "Tuning the random forest failed miserably. Let's try different versions of count vectorize paired with the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9526b06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.647552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.9, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.95, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.95, min_df=0.05)</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.575524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokenization                              preprocessing   \n",
       "5    lemmatize                            count_vectorize  \\\n",
       "6         stem   CountVectorizer(max_df=0.9, min_df=0.05)   \n",
       "7         stem  CountVectorizer(max_df=0.95, min_df=0.05)   \n",
       "8         stem        CountVectorizer(ngram_range=(1, 2))   \n",
       "9         stem  CountVectorizer(max_df=0.95, min_df=0.05)   \n",
       "\n",
       "                                          classifier     score  \n",
       "5                                     support_vector  0.647552  \n",
       "6                                    MultinomialNB()  0.612587  \n",
       "7                                    MultinomialNB()  0.612587  \n",
       "8                                    MultinomialNB()  0.690909  \n",
       "9  (DecisionTreeClassifier(max_features='sqrt', r...  0.575524  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer(min_df=0.05, max_df=0.95)\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                             columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                           columns=count.vocabulary_)\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', count, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6d986d",
   "metadata": {},
   "source": [
    "Once again, let's try adding bigrams instead of specifying document frequency limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5c1bdbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.9, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.95, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.95, min_df=0.05)</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.575524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.657343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                              preprocessing   \n",
       "6          stem   CountVectorizer(max_df=0.9, min_df=0.05)  \\\n",
       "7          stem  CountVectorizer(max_df=0.95, min_df=0.05)   \n",
       "8          stem        CountVectorizer(ngram_range=(1, 2))   \n",
       "9          stem  CountVectorizer(max_df=0.95, min_df=0.05)   \n",
       "10         stem        CountVectorizer(ngram_range=(1, 2))   \n",
       "\n",
       "                                           classifier     score  \n",
       "6                                     MultinomialNB()  0.612587  \n",
       "7                                     MultinomialNB()  0.612587  \n",
       "8                                     MultinomialNB()  0.690909  \n",
       "9   (DecisionTreeClassifier(max_features='sqrt', r...  0.575524  \n",
       "10  (DecisionTreeClassifier(max_features='sqrt', r...  0.657343  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                             columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                           columns=count.vocabulary_)\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', count, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7864f528",
   "metadata": {},
   "source": [
    "Let's tune our support vector machine, then move on to other preprocessing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ce684e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# too long\n",
    "\n",
    "# count = CountVectorizer()\n",
    "\n",
    "# final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "#                              columns=count.vocabulary_)\n",
    "# final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "#                            columns=count.vocabulary_)\n",
    "\n",
    "# scaled_X_train = pd.DataFrame(ss.fit_transform(final_X_train), index=final_X_train.index,\n",
    "#                               columns=final_X_train.columns)\n",
    "# scaled_X_val = pd.DataFrame(ss.transform(final_X_val), index=final_X_val.index,\n",
    "#                             columns=final_X_val.columns)\n",
    "\n",
    "# param_grid = [\n",
    "#     {'C': [0.01, 0.1, 1],\n",
    "#      'kernel': ['poly', 'rbf'],\n",
    "#      'gamma': [0.001, 0.005, 0.01],\n",
    "#      'class_weight': ['balanced', {0:1, 1:1, 2:1}]}\n",
    "# ]\n",
    "\n",
    "# grid_search = GridSearchCV(svc, param_grid, scoring='accuracy')\n",
    "\n",
    "# grid_search.fit(scaled_X_train, y_train)\n",
    "\n",
    "# grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a54ffb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fitting model; check training data. Is it scaled? Try fitting separately to troubleshoot.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count = CountVectorizer()\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                             columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                           columns=count.vocabulary_)\n",
    "\n",
    "scaled_X_train = pd.DataFrame(ss.fit_transform(final_X_train), index=final_X_train.index,\n",
    "                              columns=final_X_train.columns)\n",
    "scaled_X_val = pd.DataFrame(ss.transform(final_X_val), index=final_X_val.index,\n",
    "                            columns=final_X_val.columns)\n",
    "\n",
    "svc = SVC(kernel='poly')\n",
    "\n",
    "score_model(svc, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', count, svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "baed4d56",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[139], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m scaled_X_train \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(ss\u001b[38;5;241m.\u001b[39mfit_transform(final_X_train), index\u001b[38;5;241m=\u001b[39mfinal_X_train\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m      9\u001b[0m                               columns\u001b[38;5;241m=\u001b[39mfinal_X_train\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m     10\u001b[0m scaled_X_val \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(ss\u001b[38;5;241m.\u001b[39mtransform(final_X_val), index\u001b[38;5;241m=\u001b[39mfinal_X_val\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m     11\u001b[0m                             columns\u001b[38;5;241m=\u001b[39mfinal_X_val\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m---> 13\u001b[0m svc\u001b[38;5;241m.\u001b[39mfit(scaled_X_train, y_train)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/twitter-env/lib/python3.11/site-packages/sklearn/svm/_base.py:252\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    251\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 252\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/twitter-env/lib/python3.11/site-packages/sklearn/svm/_base.py:331\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    317\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    321\u001b[0m (\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 331\u001b[0m ) \u001b[38;5;241m=\u001b[39m libsvm\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    332\u001b[0m     X,\n\u001b[1;32m    333\u001b[0m     y,\n\u001b[1;32m    334\u001b[0m     svm_type\u001b[38;5;241m=\u001b[39msolver_type,\n\u001b[1;32m    335\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_class_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;241m0\u001b[39m)),\n\u001b[1;32m    338\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[1;32m    339\u001b[0m     C\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[1;32m    340\u001b[0m     nu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnu,\n\u001b[1;32m    341\u001b[0m     probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobability,\n\u001b[1;32m    342\u001b[0m     degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdegree,\n\u001b[1;32m    343\u001b[0m     shrinking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshrinking,\n\u001b[1;32m    344\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m    345\u001b[0m     cache_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_size,\n\u001b[1;32m    346\u001b[0m     coef0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef0,\n\u001b[1;32m    347\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma,\n\u001b[1;32m    348\u001b[0m     epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon,\n\u001b[1;32m    349\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[1;32m    350\u001b[0m     random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[1;32m    351\u001b[0m )\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# try fitting separately\n",
    "\n",
    "# count = CountVectorizer()\n",
    "\n",
    "svc = SVC(kernel='poly')\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                             columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                           columns=count.vocabulary_)\n",
    "\n",
    "scaled_X_train = pd.DataFrame(ss.fit_transform(final_X_train), index=final_X_train.index,\n",
    "                              columns=final_X_train.columns)\n",
    "scaled_X_val = pd.DataFrame(ss.transform(final_X_val), index=final_X_val.index,\n",
    "                            columns=final_X_val.columns)\n",
    "\n",
    "svc.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e426a7",
   "metadata": {},
   "source": [
    "Examine the performance of the best model so far (model 8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "55b114d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "count = CountVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "final_X_train = pd.DataFrame(count.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                             columns=count.vocabulary_)\n",
    "final_X_val = pd.DataFrame(count.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                           columns=count.vocabulary_)\n",
    "\n",
    "nb.fit(final_X_train, y_train)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(12, 8))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_val, nb.predict(final_X_val))).plot(ax=ax[0])\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_val, nb.predict(final_X_val), normalize='true')).plot(ax=ax[1])\n",
    "\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcfa430",
   "metadata": {},
   "source": [
    "The best model's performance corresponds loosely to class size. Let's try undersampling to get a better rate of prediction for the positive and negative classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fdfbad1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3443\n",
       "2    1919\n",
       "0     356\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "09c7d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly undersample to make class weights equal\n",
    "\n",
    "neutral_index = (y_train.loc[(y_train == 1)]).sample(356, random_state=seed).index\n",
    "positive_index = (y_train.loc[(y_train == 2)]).sample(356, random_state=seed).index\n",
    "undersampled_index = np.concatenate((neutral_index, positive_index, (y_train.loc[(y_train == 0)]).index))\n",
    "\n",
    "y_train_undersampled = y_train.loc[undersampled_index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "70f19fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    356\n",
       "2    356\n",
       "0    356\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_undersampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2c7828a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_undersampled = X_train_stems.loc[undersampled_index].copy()\n",
    "\n",
    "final_X_train_undersampled = pd.DataFrame(count.fit_transform(X_train_undersampled).todense(),\n",
    "                                          index=X_train_undersampled.index, columns=count.vocabulary_)\n",
    "final_X_val_us = pd.DataFrame(count.transform(X_val).todense(), index=X_val.index, columns=count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "eeb66db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5671328671328671"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(final_X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "nb.score(final_X_val_us, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5474ec78",
   "metadata": {},
   "source": [
    "Performance is worse. What about a different class weighting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "da77607e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6265734265734266"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly undersample to make adjust class weights\n",
    "\n",
    "neutral_index = (y_train.loc[(y_train == 1)]).sample(356*3, random_state=seed).index\n",
    "positive_index = (y_train.loc[(y_train == 2)]).sample(356*2, random_state=seed).index\n",
    "undersampled_index = np.concatenate((neutral_index, positive_index, (y_train.loc[(y_train == 0)]).index))\n",
    "\n",
    "y_train_undersampled = y_train.loc[undersampled_index].copy()\n",
    "X_train_undersampled = X_train_stems.loc[undersampled_index].copy()\n",
    "\n",
    "final_X_train_undersampled = pd.DataFrame(count.fit_transform(X_train_undersampled).todense(),\n",
    "                                          index=X_train_undersampled.index, columns=count.vocabulary_)\n",
    "final_X_val_us = pd.DataFrame(count.transform(X_val).todense(), index=X_val.index, columns=count.vocabulary_)\n",
    "\n",
    "nb.fit(final_X_train_undersampled, y_train_undersampled)\n",
    "nb.score(final_X_val_us, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66ee4c",
   "metadata": {},
   "source": [
    "Another preprocessing technique we can try is that of term frequency- inverse document frequency vectorization (similar to count vectorization, but adjusted according to how often a word appears in a particular document *versus the corpus as a whole*.)\n",
    "\n",
    "Here are the baseline results with tfidf vectorization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f7ddbd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.95, min_df=0.05)</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.575524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.657343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.648252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.673427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(kernel='poly')</td>\n",
       "      <td>0.616084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                              preprocessing   \n",
       "9          stem  CountVectorizer(max_df=0.95, min_df=0.05)  \\\n",
       "10         stem        CountVectorizer(ngram_range=(1, 2))   \n",
       "11         stem                          TfidfVectorizer()   \n",
       "12         stem                          TfidfVectorizer()   \n",
       "13         stem                          TfidfVectorizer()   \n",
       "\n",
       "                                           classifier     score  \n",
       "9   (DecisionTreeClassifier(max_features='sqrt', r...  0.575524  \n",
       "10  (DecisionTreeClassifier(max_features='sqrt', r...  0.657343  \n",
       "11                                    MultinomialNB()  0.648252  \n",
       "12  (DecisionTreeClassifier(max_features='sqrt', r...  0.673427  \n",
       "13                                 SVC(kernel='poly')  0.616084  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "final_X_train = pd.DataFrame(tfidf.fit_transform(X_train_stems).todense(), index=X_train_stems.index,\n",
    "                             columns=tfidf.vocabulary_)\n",
    "final_X_val = pd.DataFrame(tfidf.transform(X_val_stems).todense(), index=X_val_stems.index,\n",
    "                           columns=tfidf.vocabulary_)\n",
    "\n",
    "score_model(nb, final_X_train, y_train, final_X_val, y_val, 'stem', tfidf, nb)\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', tfidf, rf)\n",
    "\n",
    "scaled_X_train = pd.DataFrame(ss.fit_transform(final_X_train), index=final_X_train.index,\n",
    "                              columns=final_X_train.columns)\n",
    "scaled_X_val = pd.DataFrame(ss.transform(final_X_val), index=final_X_val.index,\n",
    "                            columns=final_X_val.columns)\n",
    "\n",
    "score_model(svc, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', tfidf, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dded13a",
   "metadata": {},
   "source": [
    "Let's tune the random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5dd5b2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.657343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.648252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.673427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(kernel='poly')</td>\n",
       "      <td>0.616084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.665035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                        preprocessing   \n",
       "10         stem  CountVectorizer(ngram_range=(1, 2))  \\\n",
       "11         stem                    TfidfVectorizer()   \n",
       "12         stem                    TfidfVectorizer()   \n",
       "13         stem                    TfidfVectorizer()   \n",
       "14         stem                    TfidfVectorizer()   \n",
       "\n",
       "                                           classifier     score  \n",
       "10  (DecisionTreeClassifier(max_features='sqrt', r...  0.657343  \n",
       "11                                    MultinomialNB()  0.648252  \n",
       "12  (DecisionTreeClassifier(max_features='sqrt', r...  0.673427  \n",
       "13                                 SVC(kernel='poly')  0.616084  \n",
       "14  (DecisionTreeClassifier(max_features='sqrt', r...  0.665035  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=seed, class_weight='balanced')\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', tfidf, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fa34e428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.648252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.673427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(kernel='poly')</td>\n",
       "      <td>0.616084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.665035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization      preprocessing   \n",
       "11         stem  TfidfVectorizer()  \\\n",
       "12         stem  TfidfVectorizer()   \n",
       "13         stem  TfidfVectorizer()   \n",
       "14         stem  TfidfVectorizer()   \n",
       "15         stem  TfidfVectorizer()   \n",
       "\n",
       "                                           classifier     score  \n",
       "11                                    MultinomialNB()  0.648252  \n",
       "12  (DecisionTreeClassifier(max_features='sqrt', r...  0.673427  \n",
       "13                                 SVC(kernel='poly')  0.616084  \n",
       "14  (DecisionTreeClassifier(max_features='sqrt', r...  0.665035  \n",
       "15  (DecisionTreeClassifier(max_features='sqrt', r...  0.671329  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=seed, n_estimators=200)\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', tfidf, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7ef65b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.673427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(kernel='poly')</td>\n",
       "      <td>0.616084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.665035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=2, max_featu...</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization      preprocessing   \n",
       "12         stem  TfidfVectorizer()  \\\n",
       "13         stem  TfidfVectorizer()   \n",
       "14         stem  TfidfVectorizer()   \n",
       "15         stem  TfidfVectorizer()   \n",
       "16         stem  TfidfVectorizer()   \n",
       "\n",
       "                                           classifier     score  \n",
       "12  (DecisionTreeClassifier(max_features='sqrt', r...  0.673427  \n",
       "13                                 SVC(kernel='poly')  0.616084  \n",
       "14  (DecisionTreeClassifier(max_features='sqrt', r...  0.665035  \n",
       "15  (DecisionTreeClassifier(max_features='sqrt', r...  0.671329  \n",
       "16  (DecisionTreeClassifier(max_depth=2, max_featu...  0.604895  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=seed, max_depth=2)\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', tfidf, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e3e4c562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(kernel='poly')</td>\n",
       "      <td>0.616084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.665035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=2, max_featu...</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>0.607692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization      preprocessing   \n",
       "13         stem  TfidfVectorizer()  \\\n",
       "14         stem  TfidfVectorizer()   \n",
       "15         stem  TfidfVectorizer()   \n",
       "16         stem  TfidfVectorizer()   \n",
       "17         stem  TfidfVectorizer()   \n",
       "\n",
       "                                           classifier     score  \n",
       "13                                 SVC(kernel='poly')  0.616084  \n",
       "14  (DecisionTreeClassifier(max_features='sqrt', r...  0.665035  \n",
       "15  (DecisionTreeClassifier(max_features='sqrt', r...  0.671329  \n",
       "16  (DecisionTreeClassifier(max_depth=2, max_featu...  0.604895  \n",
       "17  (DecisionTreeClassifier(max_depth=10, max_feat...  0.607692  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=seed, max_depth=10)\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', tfidf, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4008a54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.665035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=2, max_featu...</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>0.607692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=20, max_feat...</td>\n",
       "      <td>0.626573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization      preprocessing   \n",
       "14         stem  TfidfVectorizer()  \\\n",
       "15         stem  TfidfVectorizer()   \n",
       "16         stem  TfidfVectorizer()   \n",
       "17         stem  TfidfVectorizer()   \n",
       "18         stem  TfidfVectorizer()   \n",
       "\n",
       "                                           classifier     score  \n",
       "14  (DecisionTreeClassifier(max_features='sqrt', r...  0.665035  \n",
       "15  (DecisionTreeClassifier(max_features='sqrt', r...  0.671329  \n",
       "16  (DecisionTreeClassifier(max_depth=2, max_featu...  0.604895  \n",
       "17  (DecisionTreeClassifier(max_depth=10, max_feat...  0.607692  \n",
       "18  (DecisionTreeClassifier(max_depth=20, max_feat...  0.626573  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=seed, max_depth=20)\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', tfidf, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e74d3765",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=2, max_featu...</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>0.607692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=20, max_feat...</td>\n",
       "      <td>0.626573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=100, max_fea...</td>\n",
       "      <td>0.679720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization      preprocessing   \n",
       "15         stem  TfidfVectorizer()  \\\n",
       "16         stem  TfidfVectorizer()   \n",
       "17         stem  TfidfVectorizer()   \n",
       "18         stem  TfidfVectorizer()   \n",
       "19         stem  TfidfVectorizer()   \n",
       "\n",
       "                                           classifier     score  \n",
       "15  (DecisionTreeClassifier(max_features='sqrt', r...  0.671329  \n",
       "16  (DecisionTreeClassifier(max_depth=2, max_featu...  0.604895  \n",
       "17  (DecisionTreeClassifier(max_depth=10, max_feat...  0.607692  \n",
       "18  (DecisionTreeClassifier(max_depth=20, max_feat...  0.626573  \n",
       "19  (DecisionTreeClassifier(max_depth=100, max_fea...  0.679720  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=seed, max_depth=100)\n",
    "\n",
    "score_model(rf, final_X_train, y_train, final_X_val, y_val, 'stem', tfidf, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3932dfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.14      0.24        78\n",
      "           1       0.68      0.91      0.78       865\n",
      "           2       0.68      0.36      0.47       487\n",
      "\n",
      "    accuracy                           0.68      1430\n",
      "   macro avg       0.70      0.47      0.50      1430\n",
      "weighted avg       0.68      0.68      0.64      1430\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rf.fit(final_X_train, y_train)\n",
    "\n",
    "print(classification_report(y_val, rf.predict(final_X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "154ab0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    865\n",
       "2    487\n",
       "0     78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d04a8462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.85"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "865*0.09"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3642f236",
   "metadata": {},
   "source": [
    "Our best classifier so far has a 91% recall of neutral tweets, a 14% recall of negative tweets and a 36% recall of positive tweets. Precision is much higher, with 73% precision for negative tweets, and 68% precision for both neutral and positive tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca742ad",
   "metadata": {},
   "source": [
    "This [paper](http://www.lrec-conf.org/proceedings/lrec2014/pdf/483_Paper.pdf) makes me feel a little better about the results, although the paper was written in 2014."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca4b6cd",
   "metadata": {},
   "source": [
    "Another technique for preprocessing is to use word embeddings to vectorize the tweets, to avoid the sparsity seen with count vectorization and tfidf vectorization.\n",
    "\n",
    "I will try using the pretrained GloVe embeddings which were trained on tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6704dfb",
   "metadata": {},
   "source": [
    "We will use gensim to download the pretrained embeddings, but first, let's define a function to get the mean of the word vectors for all words in a tweet, given their GloVe embeddings.\n",
    "\n",
    "Based on the average length (in words) of a tweet in this corpus, the function finds the zero-padded mean of the first 21 words in the tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5c04b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_embeddings must be stored in a variable called glove for this function to work\n",
    "\n",
    "def get_mean_word_vector(tweet):\n",
    "    '''Takes in a string (tweet) and returns the mean word vector of the tweet based on GloVe embeddings and a\n",
    "    normalized tweet \"length\" of 21 words.'''\n",
    "    # hold the GloVe embeddings for each word in the tweet\n",
    "    glove_embeddings = []\n",
    "    \n",
    "    # iterate over each token in the tweet to add its embedding to the list\n",
    "    for token in tweet.split():\n",
    "        try:\n",
    "            glove_embeddings.append(glove[token])\n",
    "        except:\n",
    "            # this token isn't in the GloVe vocab =(\n",
    "            continue\n",
    "    # take the padded mean of the first 21 words in the tweet\n",
    "    if len(glove_embeddings) >= 21:\n",
    "        padded_tweet = glove_embeddings[:21]\n",
    "    elif len(glove_embeddings) >= 1:\n",
    "        padded_tweet = glove_embeddings\n",
    "    else:\n",
    "        padded_tweet = np.array([np.zeros((50,)) for x in range(21)]) # need an array of arrays to output correct type\n",
    "    return np.sum(padded_tweet, axis=0) / 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afb9de9",
   "metadata": {},
   "source": [
    "Second, define a function which transforms a dataframe of tweet data into a dataframe in which each column represents a dimension of the mean word vector of a tweet (based on glove embeddings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "75447202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_embed(X_train, glove_dimensions):\n",
    "    '''Get mean word vector for each tweet in df X_train based on GloVe embeddings.'''\n",
    "    embedded_series = X_train.apply(get_mean_word_vector)\n",
    "    \n",
    "    text_features = {}\n",
    "    \n",
    "    for i in range(glove_dimensions):\n",
    "        feature = f'feature_{i}'\n",
    "        values = [embedding[i] for embedding in embedded_series.values]\n",
    "        text_features[feature] = values\n",
    "    \n",
    "    return pd.DataFrame(text_features, index=X_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e13053",
   "metadata": {},
   "source": [
    "Now we can iterate over several versions of the GloVe embeddings obtained from twitter data (with different numbers of dimensions for the embeddings) and record the model score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ff50e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "glove_options = ['glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "for which_glove in glove_options:\n",
    "    glove = gensim.downloader.load(which_glove)\n",
    "    n_dim = int(which_glove.split('-')[-1]) # number after last dash is the dimensions of the embeddings\n",
    "    final_X_train = glove_embed(X_train_stems, n_dim)\n",
    "    final_X_val = glove_embed(X_val_stems, n_dim)\n",
    "    # using naive bayes as baseline; we need to scale between 0 and 1 to make all features positive (not an issue\n",
    "    # with count or tfidf vectorization, just embeddings) so use min max scaler instead of standard scaler\n",
    "    mms = MinMaxScaler()\n",
    "    scaled_X_train = mms.fit_transform(final_X_train)\n",
    "    scaled_X_val = mms.transform(final_X_val)\n",
    "    score_model(nb, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', which_glove, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "208e4c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.676923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.684615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stem</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.653147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.679021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>naive_bayes</td>\n",
       "      <td>0.683916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lemmatize</td>\n",
       "      <td>count_vectorize</td>\n",
       "      <td>support_vector</td>\n",
       "      <td>0.647552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.9, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.95, min_df=0.05)</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.612587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.690909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(max_df=0.95, min_df=0.05)</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.575524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stem</td>\n",
       "      <td>CountVectorizer(ngram_range=(1, 2))</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.657343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.648252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.673427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>SVC(kernel='poly')</td>\n",
       "      <td>0.616084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.665035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.671329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=2, max_featu...</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>0.607692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=20, max_feat...</td>\n",
       "      <td>0.626573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>stem</td>\n",
       "      <td>TfidfVectorizer()</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=100, max_fea...</td>\n",
       "      <td>0.679720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-25</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-50</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-100</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.605594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                              preprocessing   \n",
       "0          stem                            count_vectorize  \\\n",
       "1          stem                            count_vectorize   \n",
       "2          stem                            count_vectorize   \n",
       "3     lemmatize                            count_vectorize   \n",
       "4     lemmatize                            count_vectorize   \n",
       "5     lemmatize                            count_vectorize   \n",
       "6          stem   CountVectorizer(max_df=0.9, min_df=0.05)   \n",
       "7          stem  CountVectorizer(max_df=0.95, min_df=0.05)   \n",
       "8          stem        CountVectorizer(ngram_range=(1, 2))   \n",
       "9          stem  CountVectorizer(max_df=0.95, min_df=0.05)   \n",
       "10         stem        CountVectorizer(ngram_range=(1, 2))   \n",
       "11         stem                          TfidfVectorizer()   \n",
       "12         stem                          TfidfVectorizer()   \n",
       "13         stem                          TfidfVectorizer()   \n",
       "14         stem                          TfidfVectorizer()   \n",
       "15         stem                          TfidfVectorizer()   \n",
       "16         stem                          TfidfVectorizer()   \n",
       "17         stem                          TfidfVectorizer()   \n",
       "18         stem                          TfidfVectorizer()   \n",
       "19         stem                          TfidfVectorizer()   \n",
       "20         stem                           glove-twitter-25   \n",
       "21         stem                           glove-twitter-50   \n",
       "22         stem                          glove-twitter-100   \n",
       "23         stem                          glove-twitter-200   \n",
       "\n",
       "                                           classifier     score  \n",
       "0                                       random_forest  0.676923  \n",
       "1                                         naive_bayes  0.684615  \n",
       "2                                      support_vector  0.653147  \n",
       "3                                       random_forest  0.679021  \n",
       "4                                         naive_bayes  0.683916  \n",
       "5                                      support_vector  0.647552  \n",
       "6                                     MultinomialNB()  0.612587  \n",
       "7                                     MultinomialNB()  0.612587  \n",
       "8                                     MultinomialNB()  0.690909  \n",
       "9   (DecisionTreeClassifier(max_features='sqrt', r...  0.575524  \n",
       "10  (DecisionTreeClassifier(max_features='sqrt', r...  0.657343  \n",
       "11                                    MultinomialNB()  0.648252  \n",
       "12  (DecisionTreeClassifier(max_features='sqrt', r...  0.673427  \n",
       "13                                 SVC(kernel='poly')  0.616084  \n",
       "14  (DecisionTreeClassifier(max_features='sqrt', r...  0.665035  \n",
       "15  (DecisionTreeClassifier(max_features='sqrt', r...  0.671329  \n",
       "16  (DecisionTreeClassifier(max_depth=2, max_featu...  0.604895  \n",
       "17  (DecisionTreeClassifier(max_depth=10, max_feat...  0.607692  \n",
       "18  (DecisionTreeClassifier(max_depth=20, max_feat...  0.626573  \n",
       "19  (DecisionTreeClassifier(max_depth=100, max_fea...  0.679720  \n",
       "20                                    MultinomialNB()  0.604895  \n",
       "21                                    MultinomialNB()  0.604895  \n",
       "22                                    MultinomialNB()  0.604895  \n",
       "23                                    MultinomialNB()  0.605594  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364f373",
   "metadata": {},
   "source": [
    "Let's give glove a chance with a different type of model - random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d20a9cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-25</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-50</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-100</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.605594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization      preprocessing   \n",
       "20         stem   glove-twitter-25  \\\n",
       "21         stem   glove-twitter-50   \n",
       "22         stem  glove-twitter-100   \n",
       "23         stem  glove-twitter-200   \n",
       "24         stem  glove-twitter-200   \n",
       "\n",
       "                                           classifier     score  \n",
       "20                                    MultinomialNB()  0.604895  \n",
       "21                                    MultinomialNB()  0.604895  \n",
       "22                                    MultinomialNB()  0.604895  \n",
       "23                                    MultinomialNB()  0.605594  \n",
       "24  (DecisionTreeClassifier(max_features='sqrt', r...  0.653846  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=seed)\n",
    "\n",
    "# last glove embedding was best (200-dimensional) so no need to re-preprocess data\n",
    "score_model(rf, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', which_glove, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b06caf",
   "metadata": {},
   "source": [
    "This may seem like an odd approach, but I wonder if PCA could help our machine learning algorithm to learn from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9647d83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "pca.fit(scaled_X_train)\n",
    "\n",
    "# how many components must be kept to explain roughly 95% of the variance in the data?\n",
    "np.argmax(np.isclose(np.array([0.95]*200), np.cumsum(pca.explained_variance_ratio_), 0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "46cc5b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-50</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-100</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.605594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>stem</td>\n",
       "      <td>[glove-twitter-200, PCA(n_components=133)]</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.640559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                               preprocessing   \n",
       "21         stem                            glove-twitter-50  \\\n",
       "22         stem                           glove-twitter-100   \n",
       "23         stem                           glove-twitter-200   \n",
       "24         stem                           glove-twitter-200   \n",
       "25         stem  [glove-twitter-200, PCA(n_components=133)]   \n",
       "\n",
       "                                           classifier     score  \n",
       "21                                    MultinomialNB()  0.604895  \n",
       "22                                    MultinomialNB()  0.604895  \n",
       "23                                    MultinomialNB()  0.605594  \n",
       "24  (DecisionTreeClassifier(max_features='sqrt', r...  0.653846  \n",
       "25  (DecisionTreeClassifier(max_features='sqrt', r...  0.640559  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=133)\n",
    "\n",
    "reduced_X_train = pca.fit_transform(scaled_X_train)\n",
    "reduced_X_val = pca.transform(scaled_X_val)\n",
    "\n",
    "score_model(rf, reduced_X_train, y_train, reduced_X_val, y_val, 'stem', [which_glove, pca], rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f2357d",
   "metadata": {},
   "source": [
    "Reducing the dimensionality of the glove embeddings artificially didn't have a positive effect on the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe19535",
   "metadata": {},
   "source": [
    "One last technique we will try (prior to stacking) is generating our own word embeddings based on the tweets in our corpus, then creating a mean word vector for each tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f739c2",
   "metadata": {},
   "source": [
    "First, we define a helper function to get the mean word vector for each tweet (again, assuming a tweet length of 21 words.) Notice that the word2vec model we train has to be passed into the function as well as the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a03a5649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes in a word2vec model, w2v\n",
    "def get_custom_mean_word_vector(tweet, w2v):\n",
    "    '''Takes in a string (tweet) and returns the mean word vector of the tweet based on custom word2vec embeddings\n",
    "    and a normalized tweet \"length\" of 21 words.'''\n",
    "    embeddings = []\n",
    "    for token in tweet.split():\n",
    "        try:\n",
    "            embeddings.append(w2v.wv[token])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    # check number of embeddings in tweet and pad or trim as needed\n",
    "    if len(embeddings) >= 21:\n",
    "        padded_tweet = embeddings[:21]\n",
    "    elif len(embeddings) >= 1:\n",
    "        padded_tweet = embeddings\n",
    "    else:\n",
    "        padded_tweet = np.array([np.zeros((w2v.vector_size,)) for x in range(21)])\n",
    "        \n",
    "    return np.sum(padded_tweet, axis=0) / 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e976fa0d",
   "metadata": {},
   "source": [
    "Next, we develop a function to feed the embeddings of a Word2Vec model to our helper function above to determine the mean word vector for each tweet in our training data, then produce and return a matrix in which each column corresponds to a dimension of the mean word embedding for that tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a50c5b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec model needs to be FIT (instantiated) before calling this function; pass as 2nd arg\n",
    "def custom_embed(X_train, w2v):\n",
    "    '''Takes in training data and an instantiated gensim Word2Vec model; returns the matrix form of the training\n",
    "    data based on a mean word vector of length 21 words and the embeddings from Word2Vec model.'''\n",
    "    \n",
    "    # apply helper function to X_train to get mean word vector for each tweet\n",
    "    embedded_series = X_train.apply(get_custom_mean_word_vector, args=(w2v,))\n",
    "    \n",
    "    # convert embeddings to matrix form (each col corresponds to a dimension of the mean word embedding)\n",
    "    text_features = {}\n",
    "    \n",
    "    for i in range(w2v.vector_size):\n",
    "        feature = f'feature_{i}'\n",
    "        values = [embedding[i] for embedding in embedded_series.values]\n",
    "        text_features[feature] = values\n",
    "    \n",
    "    return pd.DataFrame(text_features, index=X_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25504241",
   "metadata": {},
   "source": [
    "Now, we can train a \"baseline\" embedding space and pass those embeddings to a classifier (in this case, Naive Bayes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "119f2db6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-100</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.605594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>stem</td>\n",
       "      <td>[glove-twitter-200, PCA(n_components=133)]</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.640559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                                      preprocessing   \n",
       "22         stem                                  glove-twitter-100  \\\n",
       "23         stem                                  glove-twitter-200   \n",
       "24         stem                                  glove-twitter-200   \n",
       "25         stem         [glove-twitter-200, PCA(n_components=133)]   \n",
       "26         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0....   \n",
       "\n",
       "                                           classifier     score  \n",
       "22                                    MultinomialNB()  0.604895  \n",
       "23                                    MultinomialNB()  0.605594  \n",
       "24  (DecisionTreeClassifier(max_features='sqrt', r...  0.653846  \n",
       "25  (DecisionTreeClassifier(max_features='sqrt', r...  0.640559  \n",
       "26                                    MultinomialNB()  0.604895  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# try default settings for training first\n",
    "w2v = Word2Vec(X_train_stems.map(lambda x: x.split()))\n",
    "\n",
    "scaled_X_train = mms.fit_transform(custom_embed(X_train_stems, w2v))\n",
    "scaled_X_val = mms.transform(custom_embed(X_val_stems, w2v))\n",
    "\n",
    "score_model(nb, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', w2v, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "64979331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.605594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>stem</td>\n",
       "      <td>[glove-twitter-200, PCA(n_components=133)]</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.640559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0.01&gt;</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.595804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                                      preprocessing   \n",
       "23         stem                                  glove-twitter-200  \\\n",
       "24         stem                                  glove-twitter-200   \n",
       "25         stem         [glove-twitter-200, PCA(n_components=133)]   \n",
       "26         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0....   \n",
       "27         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0.01>   \n",
       "\n",
       "                                           classifier     score  \n",
       "23                                    MultinomialNB()  0.605594  \n",
       "24  (DecisionTreeClassifier(max_features='sqrt', r...  0.653846  \n",
       "25  (DecisionTreeClassifier(max_features='sqrt', r...  0.640559  \n",
       "26                                    MultinomialNB()  0.604895  \n",
       "27                                    MultinomialNB()  0.595804  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try varying the settings for training the neural net which produces word embeddings\n",
    "# adjust learning rate\n",
    "w2v = Word2Vec(X_train_stems.map(lambda x: x.split()), alpha=0.01)\n",
    "\n",
    "scaled_X_train = mms.fit_transform(custom_embed(X_train_stems, w2v))\n",
    "scaled_X_val = mms.transform(custom_embed(X_val_stems, w2v))\n",
    "\n",
    "score_model(nb, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', w2v, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e54484c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>stem</td>\n",
       "      <td>glove-twitter-200</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>stem</td>\n",
       "      <td>[glove-twitter-200, PCA(n_components=133)]</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.640559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0.01&gt;</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.595804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                                      preprocessing   \n",
       "24         stem                                  glove-twitter-200  \\\n",
       "25         stem         [glove-twitter-200, PCA(n_components=133)]   \n",
       "26         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0....   \n",
       "27         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0.01>   \n",
       "28         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0....   \n",
       "\n",
       "                                           classifier     score  \n",
       "24  (DecisionTreeClassifier(max_features='sqrt', r...  0.653846  \n",
       "25  (DecisionTreeClassifier(max_features='sqrt', r...  0.640559  \n",
       "26                                    MultinomialNB()  0.604895  \n",
       "27                                    MultinomialNB()  0.595804  \n",
       "28                                    MultinomialNB()  0.604196  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try varying the settings for training the neural net which produces word embeddings\n",
    "# our documents are short, so try adjusting batch size & window\n",
    "w2v = Word2Vec(X_train_stems.map(lambda x: x.split()), window=3, batch_words=300)\n",
    "\n",
    "scaled_X_train = mms.fit_transform(custom_embed(X_train_stems, w2v))\n",
    "scaled_X_val = mms.transform(custom_embed(X_val_stems, w2v))\n",
    "\n",
    "score_model(nb, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', w2v, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e20d7334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>stem</td>\n",
       "      <td>[glove-twitter-200, PCA(n_components=133)]</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>0.640559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0.01&gt;</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.595804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=200, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                                      preprocessing   \n",
       "25         stem         [glove-twitter-200, PCA(n_components=133)]  \\\n",
       "26         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0....   \n",
       "27         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0.01>   \n",
       "28         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0....   \n",
       "29         stem  Word2Vec<vocab=1641, vector_size=200, alpha=0....   \n",
       "\n",
       "                                           classifier     score  \n",
       "25  (DecisionTreeClassifier(max_features='sqrt', r...  0.640559  \n",
       "26                                    MultinomialNB()  0.604895  \n",
       "27                                    MultinomialNB()  0.595804  \n",
       "28                                    MultinomialNB()  0.604196  \n",
       "29                                    MultinomialNB()  0.581818  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try varying the settings for training the neural net which produces word embeddings\n",
    "# adjust dimensionality of embeddings\n",
    "w2v = Word2Vec(X_train_stems.map(lambda x: x.split()), vector_size=200)\n",
    "\n",
    "scaled_X_train = mms.fit_transform(custom_embed(X_train_stems, w2v))\n",
    "scaled_X_val = mms.transform(custom_embed(X_val_stems, w2v))\n",
    "\n",
    "score_model(nb, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', w2v, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "52a4a622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenization</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0.01&gt;</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.595804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=100, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=200, alpha=0....</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.581818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>stem</td>\n",
       "      <td>Word2Vec&lt;vocab=1641, vector_size=50, alpha=0.025&gt;</td>\n",
       "      <td>MultinomialNB()</td>\n",
       "      <td>0.604895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tokenization                                      preprocessing   \n",
       "26         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0....  \\\n",
       "27         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0.01>   \n",
       "28         stem  Word2Vec<vocab=1641, vector_size=100, alpha=0....   \n",
       "29         stem  Word2Vec<vocab=1641, vector_size=200, alpha=0....   \n",
       "30         stem  Word2Vec<vocab=1641, vector_size=50, alpha=0.025>   \n",
       "\n",
       "         classifier     score  \n",
       "26  MultinomialNB()  0.604895  \n",
       "27  MultinomialNB()  0.595804  \n",
       "28  MultinomialNB()  0.604196  \n",
       "29  MultinomialNB()  0.581818  \n",
       "30  MultinomialNB()  0.604895  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try varying the settings for training the neural net which produces word embeddings\n",
    "# adjust dimensionality of embeddings\n",
    "w2v = Word2Vec(X_train_stems.map(lambda x: x.split()), vector_size=50)\n",
    "\n",
    "scaled_X_train = mms.fit_transform(custom_embed(X_train_stems, w2v))\n",
    "scaled_X_val = mms.transform(custom_embed(X_val_stems, w2v))\n",
    "\n",
    "score_model(nb, scaled_X_train, y_train, scaled_X_val, y_val, 'stem', w2v, nb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-env",
   "language": "python",
   "name": "twitter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
